{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":13036470,"sourceType":"datasetVersion","datasetId":8254667},{"sourceId":13048123,"sourceType":"datasetVersion","datasetId":8262539},{"sourceId":13479407,"sourceType":"datasetVersion","datasetId":8557732},{"sourceId":13517403,"sourceType":"datasetVersion","datasetId":8582617},{"sourceId":13521054,"sourceType":"datasetVersion","datasetId":8585218},{"sourceId":13556755,"sourceType":"datasetVersion","datasetId":8610813},{"sourceId":13722194,"sourceType":"datasetVersion","datasetId":8730399}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load and preprocess data","metadata":{"id":"a1611303"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Dropout,Bidirectional,Conv1D,MaxPooling1D,TimeDistributed\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport time, random,os\n\nseed = 42\nnp.random.seed(seed)\nrandom.seed(seed)\ntf.random.set_seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\n\n# Enable mixed precision globally\nmixed_precision.set_global_policy(\"mixed_float16\")\nprint(\"Compute dtype:\", tf.keras.mixed_precision.global_policy().compute_dtype)\nprint(\"Variable dtype:\", tf.keras.mixed_precision.global_policy().variable_dtype)\n\n# Load the trajectory data from the CSV file\ndf_main = pd.read_csv(\"/kaggle/input/57-61-tracks-with-multi-hot/57-61_tracks_with_multi_hot.csv\")\n\n# Select target columns (25–36 → Python index 25:37 since end is exclusive)\ntarget_cols = df_main.columns[26:38]\n\n# Remove rows where all target values are 0\ndf = df_main[~df_main[target_cols].eq(0).all(axis=1)].copy()\n\n# Display the first 5 rows of the DataFrame\ndisplay(df.head())\n\n# Display the information about the DataFrame\ndisplay(df.info())\n\ndel df_main","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"55f617ad","outputId":"12f9e797-ea04-4f19-fd7d-57fc279b67ba","trusted":true,"execution":{"iopub.status.busy":"2026-01-11T19:04:56.720325Z","iopub.execute_input":"2026-01-11T19:04:56.720668Z","iopub.status.idle":"2026-01-11T19:05:02.137835Z","shell.execute_reply.started":"2026-01-11T19:04:56.720636Z","shell.execute_reply":"2026-01-11T19:05:02.136238Z"}},"outputs":[{"name":"stdout","text":"Compute dtype: float16\nVariable dtype: float32\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     frame  document_id  id       x      y  width  height  xVelocity  \\\n207      2           57   5  127.83  14.12   4.95    1.92     -27.08   \n208      3           57   5  126.80  14.12   4.95    1.92     -27.07   \n209      4           57   5  125.75  14.12   4.95    1.92     -27.07   \n210      5           57   5  124.67  14.12   4.95    1.92     -27.07   \n211      6           57   5  123.60  14.11   4.95    1.92     -27.06   \n\n     yVelocity  xAcceleration  ...  Ego merging into an occupied lane  \\\n207      -0.01           0.07  ...                                  0   \n208      -0.01           0.07  ...                                  0   \n209      -0.02           0.06  ...                                  0   \n210      -0.02           0.06  ...                                  0   \n211      -0.02           0.06  ...                                  0   \n\n     Ego vehicle approaching slower lead vehicle  \\\n207                                            0   \n208                                            0   \n209                                            0   \n210                                            0   \n211                                            0   \n\n     Ego vehicle driving in lane without lead vehicle  \\\n207                                                 0   \n208                                                 0   \n209                                                 0   \n210                                                 0   \n211                                                 0   \n\n     Ego vehicle overtaking vehicle in adjacent lane  \\\n207                                                0   \n208                                                0   \n209                                                0   \n210                                                0   \n211                                                0   \n\n     Ego vehicle performing lane change  \\\n207                                   0   \n208                                   0   \n209                                   0   \n210                                   0   \n211                                   0   \n\n     Ego vehicle performing lane change with vehicle behind  \\\n207                                                  0        \n208                                                  0        \n209                                                  0        \n210                                                  0        \n211                                                  0        \n\n     Lead vehicle accelerating  Lead vehicle cruising  \\\n207                          0                      1   \n208                          0                      1   \n209                          0                      1   \n210                          0                      1   \n211                          0                      1   \n\n     Lead vehicle decelerating  Vehicle overtaking ego vehicle  \n207                          0                               0  \n208                          0                               0  \n209                          0                               0  \n210                          0                               0  \n211                          0                               0  \n\n[5 rows x 38 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame</th>\n      <th>document_id</th>\n      <th>id</th>\n      <th>x</th>\n      <th>y</th>\n      <th>width</th>\n      <th>height</th>\n      <th>xVelocity</th>\n      <th>yVelocity</th>\n      <th>xAcceleration</th>\n      <th>...</th>\n      <th>Ego merging into an occupied lane</th>\n      <th>Ego vehicle approaching slower lead vehicle</th>\n      <th>Ego vehicle driving in lane without lead vehicle</th>\n      <th>Ego vehicle overtaking vehicle in adjacent lane</th>\n      <th>Ego vehicle performing lane change</th>\n      <th>Ego vehicle performing lane change with vehicle behind</th>\n      <th>Lead vehicle accelerating</th>\n      <th>Lead vehicle cruising</th>\n      <th>Lead vehicle decelerating</th>\n      <th>Vehicle overtaking ego vehicle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>207</th>\n      <td>2</td>\n      <td>57</td>\n      <td>5</td>\n      <td>127.83</td>\n      <td>14.12</td>\n      <td>4.95</td>\n      <td>1.92</td>\n      <td>-27.08</td>\n      <td>-0.01</td>\n      <td>0.07</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>3</td>\n      <td>57</td>\n      <td>5</td>\n      <td>126.80</td>\n      <td>14.12</td>\n      <td>4.95</td>\n      <td>1.92</td>\n      <td>-27.07</td>\n      <td>-0.01</td>\n      <td>0.07</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>4</td>\n      <td>57</td>\n      <td>5</td>\n      <td>125.75</td>\n      <td>14.12</td>\n      <td>4.95</td>\n      <td>1.92</td>\n      <td>-27.07</td>\n      <td>-0.02</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>210</th>\n      <td>5</td>\n      <td>57</td>\n      <td>5</td>\n      <td>124.67</td>\n      <td>14.12</td>\n      <td>4.95</td>\n      <td>1.92</td>\n      <td>-27.07</td>\n      <td>-0.02</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>211</th>\n      <td>6</td>\n      <td>57</td>\n      <td>5</td>\n      <td>123.60</td>\n      <td>14.11</td>\n      <td>4.95</td>\n      <td>1.92</td>\n      <td>-27.06</td>\n      <td>-0.02</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 1098500 entries, 207 to 1604466\nData columns (total 38 columns):\n #   Column                                                  Non-Null Count    Dtype  \n---  ------                                                  --------------    -----  \n 0   frame                                                   1098500 non-null  int64  \n 1   document_id                                             1098500 non-null  int64  \n 2   id                                                      1098500 non-null  int64  \n 3   x                                                       1098500 non-null  float64\n 4   y                                                       1098500 non-null  float64\n 5   width                                                   1098500 non-null  float64\n 6   height                                                  1098500 non-null  float64\n 7   xVelocity                                               1098500 non-null  float64\n 8   yVelocity                                               1098500 non-null  float64\n 9   xAcceleration                                           1098500 non-null  float64\n 10  yAcceleration                                           1098500 non-null  float64\n 11  frontSightDistance                                      1098500 non-null  float64\n 12  backSightDistance                                       1098500 non-null  float64\n 13  dhw                                                     1098500 non-null  float64\n 14  thw                                                     1098500 non-null  float64\n 15  ttc                                                     1098500 non-null  float64\n 16  precedingXVelocity                                      1098500 non-null  float64\n 17  precedingId                                             1098500 non-null  int64  \n 18  followingId                                             1098500 non-null  int64  \n 19  leftPrecedingId                                         1098500 non-null  int64  \n 20  leftAlongsideId                                         1098500 non-null  int64  \n 21  leftFollowingId                                         1098500 non-null  int64  \n 22  rightPrecedingId                                        1098500 non-null  int64  \n 23  rightAlongsideId                                        1098500 non-null  int64  \n 24  rightFollowingId                                        1098500 non-null  int64  \n 25  laneId                                                  1098500 non-null  int64  \n 26  Cut-in in front of ego vehicle                          1098500 non-null  int64  \n 27  Cut-out in front of ego vehicle                         1098500 non-null  int64  \n 28  Ego merging into an occupied lane                       1098500 non-null  int64  \n 29  Ego vehicle approaching slower lead vehicle             1098500 non-null  int64  \n 30  Ego vehicle driving in lane without lead vehicle        1098500 non-null  int64  \n 31  Ego vehicle overtaking vehicle in adjacent lane         1098500 non-null  int64  \n 32  Ego vehicle performing lane change                      1098500 non-null  int64  \n 33  Ego vehicle performing lane change with vehicle behind  1098500 non-null  int64  \n 34  Lead vehicle accelerating                               1098500 non-null  int64  \n 35  Lead vehicle cruising                                   1098500 non-null  int64  \n 36  Lead vehicle decelerating                               1098500 non-null  int64  \n 37  Vehicle overtaking ego vehicle                          1098500 non-null  int64  \ndtypes: float64(14), int64(24)\nmemory usage: 326.9 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Condition: rows with negative xVelocity\nif  (df[\"xVelocity\"] < 0).any():\n    mask = df[\"xVelocity\"] < 0\n\n    # Convert xVelocity to positive\n    df.loc[mask, \"xVelocity\"] = -df.loc[mask, \"xVelocity\"]\n\n    # Flip the sign of yVelocity, xAcceleration, yAcceleration, and precedingXVelocity\n    cols_to_flip = [\"yVelocity\", \"xAcceleration\", \"yAcceleration\", \"precedingXVelocity\"]\n    df.loc[mask, cols_to_flip] = -df.loc[mask, cols_to_flip]\nelse:\n    print(\"No negative xVelocity found.\")\n\n# Check unique lane values\nunique_lanes = df['laneId'].unique()\n\n# Remap lanes based on number of unique values\nif set(unique_lanes) == {2, 3, 5, 6}:\n    mapping = {2: 6, 3: 5}  # map 2->6, 3->5\nelif set(unique_lanes) == {2, 3, 4, 6, 7, 8}:\n    mapping = {2: 8, 3: 7, 4: 6}  # map 2->8, 3->7, 4->6\nelse:\n    mapping = {}  # leave unchanged if not matching expected sets\ndel unique_lanes\n# Apply mapping\ndf['laneId'] = df['laneId'].replace(mapping)","metadata":{"id":"5El_41thYTzE","trusted":true,"execution":{"iopub.status.busy":"2026-01-11T19:05:02.138921Z","iopub.execute_input":"2026-01-11T19:05:02.139186Z","iopub.status.idle":"2026-01-11T19:05:02.239708Z","shell.execute_reply.started":"2026-01-11T19:05:02.139165Z","shell.execute_reply":"2026-01-11T19:05:02.238644Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"###### # Define mutually exclusive scenario groups\ngroup1 = [\n    \"Ego vehicle driving in lane without lead vehicle\",\n    \"Lead vehicle accelerating\",\n    \"Lead vehicle cruising\",\n    \"Lead vehicle decelerating\"\n]\ngroup2 = [\n    \"Ego merging into an occupied lane\",\n    # \"Ego vehicle performing lane change\",\n    \"Ego vehicle performing lane change with vehicle behind\"\n]\n\n# Check if more than one scenario in each group is 1\nmask_group1 = df[group1].sum(axis=1) > 1\nmask_group2 = df[group2].sum(axis=1) > 1\n\n# Combine masks\nmask = mask_group1 | mask_group2\ndel mask_group1, mask_group2\n\n# Compute transition boundaries (any scenario added or removed)\nscenario_cols = df.columns[26:38]  # all scenario columns\ny = df[scenario_cols].values\nboundary = np.zeros(len(df), dtype=int)\n\nfor t in range(1, len(df)):\n    if not np.array_equal(y[t], y[t-1]):\n        boundary[t] = 1\n\n# Create a new column with 1 if condition satisfied, else 0\ndf.insert(\n    loc=df.columns.get_loc(\"laneId\") + 1,  # insert after laneId\n    column=\"valid_mask\",                 # new column name\n    value=(~mask).astype(int)                  # convert True/False to 1/0\n)\n# Add boundary column to DataFrame\ndf.insert(\n    loc=df.columns.get_loc(\"valid_mask\") + 1,  # insert after valid_mask\n    column=\"boundary\",                 # new column name\n    value=boundary\n)\n\ndel mask","metadata":{"id":"TiCiIanfa_10","trusted":true,"execution":{"iopub.status.busy":"2026-01-11T19:05:02.241275Z","iopub.execute_input":"2026-01-11T19:05:02.241575Z","iopub.status.idle":"2026-01-11T19:05:07.282332Z","shell.execute_reply.started":"2026-01-11T19:05:02.241552Z","shell.execute_reply":"2026-01-11T19:05:07.281006Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"**Reasoning**:\nBased on the `df.info()` output, there are no missing values. Now, select relevant numerical features for the LSTM model and normalize them using StandardScaler.\n\n","metadata":{"id":"4a1f8b30"}},{"cell_type":"code","source":"# Select relevant numerical features for LSTM\nfeatures = ['x', 'y', 'xVelocity', 'yVelocity', 'xAcceleration', 'yAcceleration',\n            'frontSightDistance', 'backSightDistance', 'dhw', 'thw', 'ttc']\n\n# Extract features\nX = df[features].copy()\n\n# Create binary indicator surrounding vehicle indicators\nvehicle_cols = ['precedingId','followingId','leftPrecedingId','rightPrecedingId',\n                'leftFollowingId','rightFollowingId','leftAlongsideId','rightAlongsideId']\nfor col in vehicle_cols:\n    X['has_'+col.replace('Id','')] = (df[col] > 0).astype(int)\n\n# --- MODIFICATION START ---\n# Add the unscaled precedingXVelocity feature to the DataFrame\nX['precedingXVelocity'] = df['precedingXVelocity']\n\n# Initialize the scalers, we will fit them later\nscaler = StandardScaler()\nscaler_prec = StandardScaler()\n\n# Combine all *unscaled* features into X_scaled\n# The order of columns is critical and must match the original\nother_cols = [c for c in features]\nX_scaled_other = X[other_cols].values # These are still unscaled\nX_scaled = np.hstack([X_scaled_other, X[['precedingXVelocity'] + [c for c in X.columns if c.startswith('has_')]].values])\nX_scaled = pd.DataFrame(X_scaled, index=df.index)\n# --- MODIFICATION END ---\n\nprint(\"Shape of unscaled features:\", X_scaled.shape)\n\n# Define the sequence length (number of frames per sequence)\nsequence_length = 25  # 25 frames per second\n# Group the data by vehicle ID\ngrouped = df.groupby(['document_id','id'])\n# grouped = df.groupby('id')\ndel df\n\n# Create sequences of frames and corresponding labels\nX_sequences, y_sequences, b_sequences, valid_sequences,doc_ids, veh_ids = [], [], [], [], [], []\n\n# Define the target labels (scenario categories)\nlabels = list(scenario_cols)\ndel scenario_cols\ntest=0\n# Create sequences for each vehicle\nfor (doc_id,vehicle_id), group in grouped:  # change here\n    if len(group) < sequence_length:\n        continue\n    X_group = X_scaled.loc[group.index].values\n    y_group = group[labels].values\n    b_group = group['boundary'].values  \n    valid_group = group['valid_mask'].values\n    for i in range(len(X_group) - sequence_length + 1):\n        X_sequences.append(X_group[i:i + sequence_length])\n        y_sequences.append(y_group[i:i + sequence_length])\n        b_sequences.append(b_group[i:i + sequence_length])\n        valid_sequences.append(valid_group[i:i + sequence_length])\n        doc_ids.append(doc_id)\n        veh_ids.append(vehicle_id)\n        \nX_sequences = np.array(X_sequences)\ny_sequences = np.array(y_sequences)\nb_sequences = np.array(b_sequences) \nvalid_sequences = np.array(valid_sequences)\ndoc_ids = np.array(doc_ids)\nveh_ids = np.array(veh_ids)\n\n# Display the shapes of the sequences and labels\nprint(\"Shape of X_sequences:\", X_sequences.shape)\nprint(\"Shape of y_sequences:\", y_sequences.shape)\nprint(\"Shape of valid_sequences:\", valid_sequences.shape)\n\nprint(\"Shape of doc_id:\", doc_ids.shape)\nprint(\"Shape of veh_id:\", veh_ids.shape)\n\nX_temp, X_test, y_temp, y_test,b_temp, b_test, valid_temp, valid_test, doc_temp, doc_test, veh_temp, veh_test = train_test_split(\n    X_sequences, y_sequences, b_sequences, valid_sequences, doc_ids, veh_ids,  test_size=0.15, random_state=42\n)\nval_size = 0.15 / 0.85\nX_train, X_val, y_train, y_val, b_train, b_val, valid_train, valid_val, doc_train, doc_val, veh_train, veh_val = train_test_split(\n    X_temp, y_temp, b_temp, valid_temp, doc_temp, veh_temp, test_size=val_size, random_state=42\n)\n\ndel X_temp, y_temp, b_temp, valid_temp, veh_temp, X_sequences # Free up memory\n\n# --- NEW SCALING SECTION ---\n# Scale *after* splitting to prevent data leakage\n\nprint(\"\\nScaling data after split...\")\n\n# 1. Scale the main features (indices 0-10)\n# Fit scaler *only* on the training data\nscaler.fit(X_train[:, :, 0:11].reshape(-1, 11))\n\n# Transform all datasets\nX_train[:, :, 0:11] = scaler.transform(X_train[:, :, 0:11].reshape(-1, 11)).reshape(X_train.shape[0], sequence_length, 11)\nX_val[:, :, 0:11] = scaler.transform(X_val[:, :, 0:11].reshape(-1, 11)).reshape(X_val.shape[0], sequence_length, 11)\nX_test[:, :, 0:11] = scaler.transform(X_test[:, :, 0:11].reshape(-1, 11)).reshape(X_test.shape[0], sequence_length, 11)\n\n# 2. Scale the 'precedingXVelocity' feature (index 11)\nscaler_prec.fit(X_train[:, :, 11][X_train[:, :, 12] == 1].reshape(-1, 1))\n\n# Transform all datasets\nX_train[:, :, 11] = scaler_prec.transform(X_train[:, :, 11].reshape(-1, 1)).reshape(X_train.shape[0], sequence_length)\nX_val[:, :, 11] = scaler_prec.transform(X_val[:, :, 11].reshape(-1, 1)).reshape(X_val.shape[0], sequence_length)\nX_test[:, :, 11] = scaler_prec.transform(X_test[:, :, 11].reshape(-1, 1)).reshape(X_test.shape[0], sequence_length)\n\n# 3. Set scaled 'precedingXVelocity' to 0 where no preceding vehicle exists\n# This replicates the original np.nan_to_num(..., nan=0) logic\nX_train[:, :, 11][X_train[:, :, 12] == 0] = 0\nX_val[:, :, 11][X_val[:, :, 12] == 0] = 0\nX_test[:, :, 11][X_test[:, :, 12] == 0] = 0\n\nprint(\"Scaling complete.\")\nprint(\"Shape of X_train after scaling:\", X_train.shape)\n# print(\"Shape of X_val after scaling:\", X_val.shape)\nprint(\"Shape of X_test after scaling:\", X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T19:04:44.487164Z","iopub.execute_input":"2026-01-11T19:04:44.487529Z","iopub.status.idle":"2026-01-11T19:04:56.718816Z","shell.execute_reply.started":"2026-01-11T19:04:44.487500Z","shell.execute_reply":"2026-01-11T19:04:56.717645Z"}},"outputs":[{"name":"stdout","text":"Shape of unscaled features: (511099, 20)\nShape of X_sequences: (459964, 25, 20)\nShape of y_sequences: (459964, 25, 12)\nShape of valid_sequences: (459964, 25)\nShape of doc_id: (459964,)\nShape of veh_id: (459964,)\n\nScaling data after split...\nScaling complete.\nShape of X_train after scaling: (321974, 25, 20)\nShape of X_test after scaling: (68995, 25, 20)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**Reasoning**:\nDefine the LSTM model architecture suitable for sequence classification, including layers for feature extraction, LSTM layers for capturing temporal dependencies, and output layers for classification.","metadata":{"id":"fbef817c"}},{"cell_type":"markdown","source":"# Model defination and training\nmake sure to connect to GPU T4 if on kaggle.","metadata":{}},{"cell_type":"code","source":"try:\n    del df, scenario_cols\nexcept:\n    pass\n\n# y_train shape: (n_samples, n_labels)\nn_samples, _, n_labels = y_train.shape\n\n# count positives per label\npos_counts = np.sum(y_train, axis=0)\nneg_counts = n_samples - pos_counts\n\n# compute pos_weight for each label\npos_weights = neg_counts / (pos_counts + 1e-7)   # avoid division by zero\nneg_weights = np.ones_like(pos_weights)\n\npos_counts = np.maximum(pos_counts, 1)\nneg_counts = np.maximum(neg_counts, 1)# usually set to 1\nclass_weights = neg_counts / pos_counts\n\nprint(\"Positive weights per label:\", pos_weights)\n\n# Define the LSTM model\ninputs = Input(shape=(sequence_length, X_train.shape[2]))\nx = Bidirectional(LSTM(64, return_sequences=True))(inputs)\nx = Bidirectional(LSTM(64,return_sequences=True))(x)\nx = Bidirectional(LSTM(64,return_sequences=True))(x)\nx = Bidirectional(LSTM(64,return_sequences=True))(x)\n\nscenario_output = TimeDistributed(Dense(len(labels), activation='sigmoid', dtype='float32', name='scenario'))(x)\nmodel = Model(inputs=inputs, outputs=scenario_output)\n\n\nmodel.compile(\n    optimizer='adamw',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"a7f8c195","outputId":"bb20e319-bc52-4b2c-d352-3f72678db12d","trusted":true,"execution":{"iopub.status.busy":"2026-01-07T20:06:25.993537Z","iopub.execute_input":"2026-01-07T20:06:25.993879Z","iopub.status.idle":"2026-01-07T20:06:26.277673Z","shell.execute_reply.started":"2026-01-07T20:06:25.993856Z","shell.execute_reply":"2026-01-07T20:06:26.276647Z"}},"outputs":[{"name":"stdout","text":"Positive weights per label: [[271.39763111 189.29196216 708.19383244  34.82663848   1.85240702\n    9.19518065  53.18613261 175.71459933  13.05263617   1.02921806\n   14.19246921   8.79567374]\n [271.85932201 189.85595731 703.53829306  34.78681783   1.85291251\n    9.17199002  53.00436095 176.10341033  12.98609965   1.03147142\n   14.1317793    8.76270467]\n [273.72184298 190.19596198 701.99999985  34.75502499   1.85351933\n    9.14410838  52.84180602 175.9087912   12.91838499   1.03393535\n   14.07298347   8.73201548]\n [275.84780737 190.42330558 703.53829306  34.73914974   1.85364578\n    9.12815351  52.63551557 175.42410958  12.85191877   1.03635375\n   14.01604328   8.7021033 ]\n [278.7341442  191.10859187 705.08333318  34.72328858   1.85405051\n    9.11479015  52.46629027 175.71459933  12.78490388   1.03864881\n   13.95883665   8.67557172]\n [279.46515677 191.33811229 706.63516468  34.72725255   1.85450596\n    9.08785287  52.34227965 175.9087912   12.71385978   1.04122077\n   13.89723777   8.64860653]\n [280.69203847 191.45307829 705.08333318  34.73914974   1.85425291\n    9.08311412  52.06097561 175.42410958  12.64412238   1.04377329\n   13.84366788   8.6209287 ]\n [280.938704   191.91431994 703.53829306  34.74311723   1.85450596\n    9.06892454  52.04349259 176.10341033  12.57909831   1.04630618\n   13.79931973   8.59712659]\n [281.92970121 192.02997601 708.19383244  34.7470856    1.85478437\n    9.06577672  52.00856108 176.98452183  12.51072133   1.04880625\n   13.7343035    8.57742876]\n [282.17853999 192.84346778 711.33185825  34.73518313   1.85470843\n    9.05948699  51.85193697 176.68984546  12.446398     1.05139085\n   13.67587401   8.55129042]\n [283.93274334 193.19420988 711.33185825  34.71536328   1.8551641\n    9.04912609  51.69623568 176.49393604  12.37990359   1.05374616\n   13.62056126   8.5317801 ]\n [285.19911109 193.66384521 716.09131387  34.71140195   1.85541731\n    9.03690888  51.61872855 176.78796244  12.32232704   1.05619879\n   13.57225617   8.51403581]\n [285.45373663 194.25409338 720.91479804  34.7074415    1.85526537\n    9.03409374  51.62732919 177.37894736  12.260327     1.05878893\n   13.51510234   8.49663756]\n [286.73369077 195.32560974 719.29977613  34.72725255   1.85465781\n    9.03221786  51.56718367 177.28017718  12.19403352   1.06167598\n   13.45969372   8.48237373]\n [289.06666664 197.01599015 716.09131387  34.74311723   1.85483499\n    9.03816056  51.54144909 176.98452183  12.13268344   1.06434612\n   13.39762107   8.47205225]\n [292.23679414 199.23258705 719.29977613  34.75502499   1.85521473\n    9.04787168  51.49861405 176.68984546  12.07190126   1.06679762\n   13.34118747   8.46703911]\n [295.47697971 201.6268093  720.91479804  34.78681783   1.85541731\n    9.05320511  51.43022309 176.78796244  12.00905051   1.0690023\n   13.29280419   8.46203127]\n [299.34888057 204.34056121 722.53707849  34.79079591   1.85569589\n    9.05508885  51.36201008 176.98452183  11.9551362    1.07125166\n   13.23592873   8.45480707]\n [303.61116364 206.45747421 722.53707849  34.78681783   1.85607586\n    9.07491082  51.31946701 176.88618784  11.89494974   1.0733991\n   13.18887714   8.44898019]\n [307.10909088 209.02870188 724.1666665   34.80671708   1.8557972\n    9.09006581  51.23458793 176.49393604  11.83327355   1.07541721\n   13.13468546   8.44593088]\n [310.38684717 211.94576718 720.91479804  34.83461324   1.85577187\n    9.10590082  51.1499838  176.10341033  11.78029611   1.07798896\n   13.08460192   8.43817787]\n [314.35161603 214.65572671 722.53707849  34.86654784   1.85564523\n    9.12465017  51.07407407 176.00604727  11.72574207   1.08016384\n   13.03548387   8.43043758]\n [318.41865076 216.99187541 724.1666665   34.89053617   1.85556925\n    9.14890465  51.0909238  176.10341033  11.67165178   1.08247796\n   12.99400209   8.42353733]\n [323.24370591 220.59256709 724.1666665   34.93860922   1.85531602\n    9.16460412  51.07407407 175.9087912   11.61653605   1.08444631\n   12.95336945   8.42188277]\n [327.88049026 223.99930117 727.44796364  34.95867769   1.85584787\n    9.1884058   51.03199741 176.00604727  11.56385843   1.0868376\n   12.90696268   8.42519247]]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m20\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ cast_2 (\u001b[38;5;33mCast\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m20\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m43,520\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m12\u001b[0m)         │         \u001b[38;5;34m1,548\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ cast_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">43,520</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m341,516\u001b[0m (1.30 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">341,516</span> (1.30 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m341,516\u001b[0m (1.30 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">341,516</span> (1.30 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"**Reasoning**:\nTrain the LSTM model on the prepared data, including splitting the data into training and validation sets, and monitoring the training progress.","metadata":{"id":"e9a82482"}},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\ns = time.time()\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val), #valid_val\n    epochs=100,\n    batch_size=32,\n    sample_weight=valid_train,  # mask ambiguous frames\n    callbacks=[early_stop]\n)\ne = time.time()\nprint(f\"Training finished. Elapsed time: {(e-s)/60:.2f} minutes\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5de03c4b","outputId":"6f6ed538-31eb-48dd-fb85-91551c969def","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('/kaggle/working/ml_bi_large_v_4layers.keras')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation model performance on the test file","metadata":{}},{"cell_type":"markdown","source":"### Run the below code block if want to pre-process the test file\nSteps:\n* Run first four code blocks with training data: '01-03_tracks_with_multi_hot.csv'\n* In first code block, change file path to test file ('57-61_tracks_with_multi_hot.csv') \n* Directly run the below code blocks","metadata":{}},{"cell_type":"code","source":"\n# --- Step 1. Extract features ---\nfeatures = ['x', 'y', 'xVelocity', 'yVelocity', 'xAcceleration', 'yAcceleration',\n            'frontSightDistance', 'backSightDistance', 'dhw', 'thw', 'ttc']\n\nX_new = df[features].copy()\n\n# --- Step 2. Add binary vehicle indicators ---\nvehicle_cols = ['precedingId','followingId','leftPrecedingId','rightPrecedingId',\n                'leftFollowingId','rightFollowingId','leftAlongsideId','rightAlongsideId']\n\nfor col in vehicle_cols:\n    X_new['has_'+col.replace('Id','')] = (df[col] > 0).astype(int)\n\n# --- Step 3. Add unscaled preceding velocity ---\nX_new['precedingXVelocity'] = df['precedingXVelocity']\n\n# --- Step 4. Construct consistent column order ---\nother_cols = [c for c in features]\nX_scaled_other = X_new[other_cols].values\nX_scaled = np.hstack([\n    X_scaled_other,\n    X_new[['precedingXVelocity'] + [c for c in X_new.columns if c.startswith('has_')]].values\n])\nX_scaled = pd.DataFrame(X_scaled, index=df.index)\n\nprint(\"Shape of unscaled new features:\", X_scaled.shape)\n\n# --- Step 5. Group and create sequences ---\nsequence_length = 25\ngrouped = df.groupby(['document_id', 'id'])\n\nX_sequences_new, y_sequences_new, b_sequences_new, valid_sequences_new, doc_ids_new, veh_ids_new = [], [], [], [], [], []\nlabels = list(scenario_cols)  # reuse your label columns\ngg=[]\nfor (doc_id, vehicle_id), group in grouped:   \n    group = group.sort_values('frame')\n    if len(group) < sequence_length:\n        continue\n    gg.append(group)\n    X_group = X_scaled.loc[group.index].values\n    y_group = group[labels].values\n    b_group = group['boundary'].values\n    valid_group = group['valid_mask'].values\n    # print(len(X_group))\n    for i in range(0,len(X_group) - sequence_length + 1,sequence_length):\n        # print(i)\n        X_sequences_new.append(X_group[i:i + sequence_length])\n        y_sequences_new.append(y_group[i:i + sequence_length])\n        b_sequences_new.append(b_group[i:i + sequence_length])\n        valid_sequences_new.append(valid_group[i:i + sequence_length])\n        doc_ids_new.append(doc_id)\n        veh_ids_new.append(vehicle_id)\n    # print(\"------\")\n    # print(len(X_sequences_new))\n    # break\n\nX_sequences_new = np.array(X_sequences_new)\ny_sequences_new = np.array(y_sequences_new)\nb_sequences_new = np.array(b_sequences_new)\nvalid_sequences_new = np.array(valid_sequences_new)\nprint(\"Shape of X_sequences_new (unscaled):\", X_sequences_new.shape)\nprint(\"Shape of group (unscaled):\", X_sequences_new.shape)\n\n\n# --- Step 6. Apply previously fitted scalers ---\n# Scale features [0:11]\nX_sequences_new[:, :, 0:11] = scaler.transform(\n    X_sequences_new[:, :, 0:11].reshape(-1, 11)\n).reshape(X_sequences_new.shape[0], sequence_length, 11)\n\n# Scale 'precedingXVelocity' [index 11]\nX_sequences_new[:, :, 11] = scaler_prec.transform(\n    X_sequences_new[:, :, 11].reshape(-1, 1)\n).reshape(X_sequences_new.shape[0], sequence_length)\n\n# Set precedingXVelocity=0 when no preceding vehicle\nX_sequences_new[:, :, 11][X_sequences_new[:, :, 12] == 0] = 0\n\nprint(\"Scaling complete for new dataset.\")\nprint(\"Shape of X_sequences_new after scaling:\", X_sequences_new.shape)\nn_samples, _, n_labels = y_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Rune below code block if want to load model, otherwise skip","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel = load_model('/kaggle/input/ml-models/ml_bi_large_v_4layers.keras', compile=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T19:43:47.823115Z","iopub.execute_input":"2026-01-07T19:43:47.823529Z","iopub.status.idle":"2026-01-07T19:43:48.361839Z","shell.execute_reply.started":"2026-01-07T19:43:47.823504Z","shell.execute_reply":"2026-01-07T19:43:48.360892Z"}},"outputs":[{"name":"stderr","text":"2026-01-07 19:43:47.908789: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from sklearn.metrics import f1_score, hamming_loss, classification_report\n\ny_pred_proba_val = model.predict(X_val)\ny_pred_proba_test = model.predict(X_test)\n\n# Flatten for per-frame evaluation\ny_val_flat = y_val.reshape(-1, n_labels)\ny_pred_val_flat = y_pred_proba_val.reshape(-1, n_labels)\ny_test_flat = y_test.reshape(-1, n_labels)\ny_pred_test_flat = y_pred_proba_test.reshape(-1, n_labels)\nmask_val_flat = valid_val.reshape(-1) == 1\nmask_test_flat = valid_test.reshape(-1) == 1\n\n# Clean masked frames\ny_val_clean = y_val_flat[mask_val_flat]\ny_pred_val_clean = y_pred_val_flat[mask_val_flat]\n\n# Find optimal threshold per class\nbest_thresholds = []\nfor i in range(n_labels):\n    best_f1, best_t = 0, 0.5\n    for t in np.linspace(0.1, 0.9, 17):\n        y_bin = (y_pred_val_clean[:, i] > t).astype(int)\n        f1 = f1_score(y_val_clean[:, i], y_bin, zero_division=0)\n        if f1 > best_f1:\n            best_f1, best_t = f1, t\n    best_thresholds.append(best_t)\n\nprint(\"Optimal thresholds per class:\", best_thresholds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T19:47:07.400952Z","iopub.execute_input":"2026-01-07T19:47:07.401314Z","iopub.status.idle":"2026-01-07T19:52:59.178042Z","shell.execute_reply.started":"2026-01-07T19:47:07.401292Z","shell.execute_reply":"2026-01-07T19:52:59.177248Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2157/2157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 51ms/step\n\u001b[1m2157/2157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 50ms/step\nOptimal thresholds per class: [0.65, 0.6, 0.5, 0.5, 0.4, 0.55, 0.5, 0.55, 0.4, 0.5, 0.6, 0.55]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# --- Predict probabilities ---\ny_pred_proba_test = model.predict(X_sequences_new)\n\n# --- Apply thresholds per sequence ---\n\ny_pred_bin_seq = np.zeros_like(y_pred_proba_test)\nfor i, t in enumerate(best_thresholds):\n    y_pred_bin_seq[:, :, i] = (y_pred_proba_test[:, :, i] > t).astype(int)\n\n# --- Initialize accumulators ---\ny_true_all, y_pred_all = [], []\n \ny_true_all = y_sequences_new.reshape(-1, y_sequences_new.shape[-1]).astype(int)\ny_pred_all = y_pred_bin_seq.reshape(-1, y_pred_bin_seq.shape[-1]).astype(int)\n\n# --- Evaluate ---\nprint(\"Classification Report (sequence-level):\")\nprint(classification_report(y_true_all, y_pred_all, target_names=labels))\nprint(\"Hamming Loss:\", hamming_loss(y_true_all, y_pred_all))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T19:52:59.179422Z","iopub.execute_input":"2026-01-07T19:52:59.179789Z","iopub.status.idle":"2026-01-07T19:54:07.673421Z","shell.execute_reply.started":"2026-01-07T19:52:59.179765Z","shell.execute_reply":"2026-01-07T19:54:07.672405Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1303/1303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 49ms/step\nClassification Report (sequence-level):\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"                                                        precision    recall  f1-score   support\n\n                        Cut-in in front of ego vehicle       0.08      0.02      0.03     11033\n                       Cut-out in front of ego vehicle       0.06      0.01      0.02     10652\n                     Ego merging into an occupied lane       0.01      0.00      0.00      2332\n           Ego vehicle approaching slower lead vehicle       0.44      0.50      0.47     30837\n      Ego vehicle driving in lane without lead vehicle       0.89      0.80      0.84    423449\n       Ego vehicle overtaking vehicle in adjacent lane       0.48      0.30      0.37    105009\n                    Ego vehicle performing lane change       0.67      0.63      0.65     26696\nEgo vehicle performing lane change with vehicle behind       0.45      0.26      0.33      7621\n                             Lead vehicle accelerating       0.46      0.31      0.37    120802\n                                 Lead vehicle cruising       0.60      0.81      0.69    377158\n                             Lead vehicle decelerating       0.41      0.16      0.23     93906\n                        Vehicle overtaking ego vehicle       0.65      0.58      0.61    121244\n\n                                             micro avg       0.66      0.62      0.64   1330739\n                                             macro avg       0.43      0.36      0.38   1330739\n                                          weighted avg       0.65      0.62      0.62   1330739\n                                           samples avg       0.67      0.66      0.65   1330739\n\nHamming Loss: 0.07349572629070818\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from collections import defaultdict\n\ndependent_pairs = {\n    \"Cut-in in front of ego vehicle\": [\n        \"Lead vehicle accelerating\",\n        \"Lead vehicle cruising\",\n        \"Lead vehicle decelerating\"\n    ],\n    \"Cut-out in front of ego vehicle\": [\n        \"Ego vehicle driving in lane without lead vehicle\",\n        \"Lead vehicle cruising\",\n        \"Lead vehicle decelerating\",\n        \"Lead vehicle accelerating\"\n    ],\n    \"Ego merging into an occupied lane\": [\n        \"Lead vehicle cruising\",\n        \"Lead vehicle decelerating\",\n        \"Lead vehicle accelerating\"\n    ],\n    \"Ego vehicle performing lane change\": [\n        \"Ego vehicle driving in lane without lead vehicle\"\n    ],\n    \"Ego vehicle performing lane change with vehicle behind\": [\n        \"Ego vehicle driving in lane without lead vehicle\"\n    ],\n    \"Ego vehicle driving in lane without lead vehicle\": [\n        \"Ego vehicle approaching slower lead vehicle\",\n        \"Lead vehicle accelerating\",\n        \"Lead vehicle cruising\",\n        \"Lead vehicle decelerating\"\n    ]\n}\n\ndef compute_boundary_metrics_fast(y_true, y_pred, length=None):\n    true_boundaries = np.where((y_true[1:] == 1) & (y_true[:-1] == 0))[0] + 1\n    pred_boundaries = np.where((y_pred[1:] == 1) & (y_pred[:-1] == 0))[0] + 1\n    if len(true_boundaries) == 0 or len(pred_boundaries) == 0:\n        return np.nan\n    diffs = []\n    for tb in true_boundaries:\n        idx = np.searchsorted(pred_boundaries, tb)\n        cands = []\n        if idx > 0: cands.append(abs(tb - pred_boundaries[idx - 1]))\n        if idx < len(pred_boundaries): cands.append(abs(tb - pred_boundaries[idx]))\n        diffs.append(min(cands))\n    mabe = float(np.mean(diffs))\n    if length is not None:\n        return mabe / length  # <= normalization step\n    return mabe\n\ndef pretty_transition_report(\n    y_sequences,            # (N_seq, seq_len, n_labels) ground truth (0/1)\n    y_pred_proba=None,      # (N_seq, seq_len, n_labels) probabilities OR None if y_pred_bin provided\n    doc_ids=None,           # length N_seq, mapping sequence -> doc_id\n    veh_ids=None,           # length N_seq, mapping sequence -> vehicle id\n    labels=None,            # list of n_labels label names\n    best_thresholds=None,   # list/array of per-class thresholds (used if y_pred_proba provided)\n    y_pred_bin=None,        # optional precomputed binary predictions (N_seq, seq_len, n_labels)\n    dependent_pairs=None,   # dictionary of dependent pairs as you provided\n    match_tolerance_prev=1, # tolerance in frames for matching predicted prev_end to true prev_end (default ±1)\n    allow_curr_offset=1     # allow curr_start == prev_end or prev_end + 1 (default 1)\n):\n    \"\"\"Compute boundary MABE, missed scenario-per-vehicle, and transition MABE+missed per dependent pair.\n\n    Returns dict with 'boundary_summary', 'missed_percent_vehicle', 'transition_summary', etc.\n    \"\"\"\n    # Basic checks\n    assert labels is not None, \"Provide labels list\"\n    n_seq, seq_len, n_labels = y_sequences.shape\n\n    # Build binary predictions if not provided\n    if y_pred_bin is None:\n        if y_pred_proba is None or best_thresholds is None:\n            raise ValueError(\"Either y_pred_bin OR (y_pred_proba and best_thresholds) must be provided.\")\n        thr = np.array(best_thresholds).reshape(1, 1, -1)\n        y_pred_bin = (y_pred_proba.astype(np.float32) > thr).astype(np.int32)\n    else:\n        y_pred_bin = y_pred_bin.astype(np.int32)\n\n    # ensure y_sequences ints\n    y_sequences = y_sequences.astype(np.int32)\n\n    # 1) Build mapping (doc,veh) -> ordered list of sequence indices\n    seqs_by_vehicle = defaultdict(list)\n    for idx, (d, v) in enumerate(zip(doc_ids, veh_ids)):\n        seqs_by_vehicle[(d, v)].append(idx)\n\n    # 2) Boundary MABE per label averaged across vehicles\n    boundary_results = defaultdict(list)\n    for (d, v), seq_indices in seqs_by_vehicle.items():\n        y_true_vehicle = np.concatenate([y_sequences[i] for i in seq_indices], axis=0)\n        y_pred_vehicle = np.concatenate([y_pred_bin[i] for i in seq_indices], axis=0)\n        for i, lab in enumerate(labels):\n            mabe = compute_boundary_metrics_fast(y_true_vehicle[:, i], y_pred_vehicle[:, i],length=len(y_true_vehicle))\n            if not np.isnan(mabe):\n                boundary_results[lab].append(mabe)\n    boundary_summary = {lab: float(np.mean(vals)) if len(vals) > 0 else np.nan\n                        for lab, vals in boundary_results.items() for _ in [0]}\n    # preserve order and fill missing labels\n    boundary_summary = {lab: (boundary_summary.get(lab, np.nan)) for lab in labels}\n    avg_mabe = float(np.nanmean([v for v in boundary_summary.values() if not np.isnan(v)])) if any(\n        not np.isnan(v) for v in boundary_summary.values()) else np.nan\n\n    # 3) Missed Scenario Detection Rate per vehicle\n    missed_counts_vehicle = defaultdict(int)\n    total_support_vehicle = defaultdict(int)\n    for (d, v), seq_indices in seqs_by_vehicle.items():\n        y_true_vehicle = np.concatenate([y_sequences[i] for i in seq_indices], axis=0)\n        y_pred_vehicle = np.concatenate([y_pred_bin[i] for i in seq_indices], axis=0)\n        for i, lab in enumerate(labels):\n            if y_true_vehicle[:, i].sum() > 0:\n                total_support_vehicle[lab] += 1\n                if y_pred_vehicle[:, i].sum() == 0:\n                    missed_counts_vehicle[lab] += 1\n    missed_percent_vehicle = {lab: (100.0 * missed_counts_vehicle.get(lab, 0) / total_support_vehicle.get(lab, 1))\n                              if total_support_vehicle.get(lab, 0) > 0 else np.nan for lab in labels}\n\n    # Simplified per-vehicle transition evaluation WITHOUT match_tolerance_prev\n    label2idx = {l: i for i, l in enumerate(labels)}\n    transition_results = defaultdict(list)   # per-pair list of per-instance distances\n    transition_support = defaultdict(int)    # number of true transition instances (actual)\n    missed_transitions = defaultdict(int)    # number of true instances missed\n    \n    allow_curr_offset = 1  # allow predicted curr_start == pred_prev_end or pred_prev_end + 1\n    \n    def ends(idx_seq):   # 1->0 ends, returns indices of the frame after end\n        return np.where((idx_seq[:-1] == 1) & (idx_seq[1:] == 0))[0] + 1\n    \n    def starts(idx_seq): # 0->1 starts, returns indices\n        return np.where((idx_seq[1:] == 1) & (idx_seq[:-1] == 0))[0] + 1\n    \n    # loop per vehicle\n    for (d, v), seq_indices in seqs_by_vehicle.items():\n        # reconstruct whole vehicle timeline\n        y_true_vehicle = np.concatenate([y_sequences[i] for i in seq_indices], axis=0)\n        y_pred_vehicle = np.concatenate([y_pred_bin[i] for i in seq_indices], axis=0)\n        vehicle_len = len(y_true_vehicle)\n    \n        for prev_label, next_labels in (dependent_pairs or {}).items():\n            if prev_label not in label2idx:\n                continue\n            p_idx = label2idx[prev_label]\n            pred_prev_end = ends(y_pred_vehicle[:, p_idx])\n    \n            for curr_label in next_labels:\n                if curr_label not in label2idx:\n                    continue\n                c_idx = label2idx[curr_label]\n    \n                true_prev_end = ends(y_true_vehicle[:, p_idx])\n                true_curr_start = starts(y_true_vehicle[:, c_idx])\n                pred_curr_start = starts(y_pred_vehicle[:, c_idx])\n    \n                # build predicted pairs in vehicle: (pred_prev_end -> pred_curr_start) where curr==prev or prev+1\n                pred_pairs_curr = []\n                if len(pred_prev_end) > 0 and len(pred_curr_start) > 0:\n                    for p in pred_prev_end:\n                        matches = pred_curr_start[(pred_curr_start == p) | (pred_curr_start == p + allow_curr_offset)]\n                        if len(matches) > 0:\n                            pred_pairs_curr.extend(list(matches))  # collect predicted curr_starts\n    \n                # For each true prev_end that actually has a following true curr_start (0 or +1)\n                for te in true_prev_end:\n                    if not (np.any(true_curr_start == te) or np.any(true_curr_start == te + 1)):\n                        continue  # not a true prev->curr instance\n    \n                    transition_support[(prev_label, curr_label)] += 1\n    \n                    if len(pred_pairs_curr) == 0:\n                        # no predicted dependent pairs anywhere in this vehicle -> missed\n                        missed_transitions[(prev_label, curr_label)] += 1\n                        continue\n    \n                    # choose the true curr_start for this instance (prefer te, else te+1)\n                    true_cs_cands = true_curr_start[(true_curr_start == te) | (true_curr_start == te + 1)]\n                    if len(true_cs_cands) > 0:\n                        true_cs = int(true_cs_cands[0])\n                    else:\n                        # fallback: nearest true curr start\n                        true_cs = int(true_curr_start[np.argmin(np.abs(true_curr_start - te))]) if len(true_curr_start) > 0 else None\n    \n                    if true_cs is None:\n                        missed_transitions[(prev_label, curr_label)] += 1\n                        continue\n    \n                    # compute distance to nearest predicted curr_start among vehicle's predicted pairs\n                    pred_cs_arr = np.array(pred_pairs_curr)\n                    best_dist = np.min(np.abs(pred_cs_arr - true_cs)) / vehicle_len \n                    transition_results[(prev_label, curr_label)].append(best_dist)\n    \n    # Final per-pair MABE (mean of per-instance distances)\n    transition_summary = {\n        pair: float(np.mean(dists)) if len(dists) > 0 else 0\n        for pair, dists in transition_results.items()\n    }\n\n    # compute missed rates and print results\n    print(\"\\nBoundary metrics per class (averaged across vehicles):\")\n    for lab in labels:\n        mabe = boundary_summary.get(lab, np.nan)\n        if np.isnan(mabe):\n            print(f\"{lab}: MABE = n/a\")\n        else:\n            print(f\"{lab}: MABE = {mabe:.2f}\")\n    print(f\"\\nAverage MABE across all classes: {avg_mabe:.4f}\\n\")\n\n    print(\"Missed Scenario Detection Rates (% of vehicles where class was present but never predicted):\")\n    for lab in labels:\n        pct = missed_percent_vehicle.get(lab, np.nan)\n        if np.isnan(pct):\n            print(f\"{lab}: n/a\")\n        else:\n            print(f\"{lab}: {pct:.2f}% missed (support: {total_support_vehicle.get(lab,0)})\")\n    avg_miss_rate = float(np.nanmean([v for v in missed_percent_vehicle.values() if not np.isnan(v)])) if any(not np.isnan(v) for v in missed_percent_vehicle.values()) else np.nan\n    print(f\"\\nAverage Miss Rate Across All Classes (per vehicle): {avg_miss_rate:.2f}%\\n\")\n\n    # overall stats\n    avg_transition_mabe = float(np.nanmean([v for v in transition_summary.values() if not np.isnan(v)])) if len(transition_summary) > 0 else np.nan\n    total_transitions = sum(transition_support.values())\n    total_missed = sum(missed_transitions.values())\n    overall_miss_rate = (total_missed / total_transitions * 100) if total_transitions > 0 else 0.0\n\n    # --- 5) Summarize transition metrics ---\n    print(\"\\nTransition-based MABE (evaluated per vehicle):\")\n    for prev_label, next_labels in dependent_pairs.items():\n        for curr_label in next_labels:\n            pair = (prev_label, curr_label)\n            total = transition_support.get(pair, 0)\n            if total == 0:\n                continue  # skip transitions that never occurred in ground truth\n    \n            missed = missed_transitions.get(pair, 0)\n            mabe_vals = transition_results.get(pair, [])\n            mean_mabe = np.mean(mabe_vals) if len(mabe_vals) > 0 else np.nan\n            missed_rate = (missed / total * 100) if total > 0 else 0.0\n    \n            print(f\"{prev_label} -> {curr_label}: \"\n                  f\"MABE = {mean_mabe:.2f} | Support = {total} | \"\n                  f\"Missed = {missed} ({missed_rate:.1f}%)\")\n    if any(v > 0 for v in transition_support.values()):\n        avg_mabe = np.nanmean([np.mean(v) for v in transition_results.values() if len(v) > 0])\n        total_transitions = sum(transition_support.values())\n        total_missed = sum(missed_transitions.values())\n        avg_miss_rate = (total_missed / total_transitions * 100) if total_transitions > 0 else 0\n        print(f\"\\nAverage Transition MABE Across All Pairs: {avg_mabe:.4f}\")\n        print(f\"Overall Missed Transition Detection Rate (per vehicle): {avg_miss_rate:.2f}%\")\n    else:\n        print(\"\\n⚠️ No valid transitions detected in the test set.\")\n\n    # Return structured results\n    return {\n        \"boundary_summary\": boundary_summary,\n        \"avg_mabe\": avg_mabe,\n        \"missed_percent_vehicle\": missed_percent_vehicle,\n        \"avg_miss_rate_vehicle\": avg_miss_rate if 'avg_miss_rate' in locals() else avg_miss_rate,\n        \"support_counts_vehicle\": {lab: total_support_vehicle.get(lab, 0) for lab in labels},\n        \"missed_counts_vehicle\": {lab: missed_counts_vehicle.get(lab, 0) for lab in labels},\n        \"transition_summary\": transition_summary,\n        \"transition_support\": dict(transition_support),\n        \"missed_transitions\": dict(missed_transitions),\n        \"avg_transition_mabe\": avg_transition_mabe,\n        \"overall_miss_rate\": overall_miss_rate\n    }\n\n# -------------------------------\n# Usage (plug your variables):\n# -------------------------------\nresult = pretty_transition_report(\n    y_sequences=y_sequences_new,\n    y_pred_proba=y_pred_proba_test,\n    doc_ids=doc_ids_new,\n    veh_ids=veh_ids_new,\n    labels=labels,\n    best_thresholds=best_thresholds,\n    y_pred_bin=y_pred_bin_seq,            # if you already have binary preds; else set None and function will threshold\n    dependent_pairs=dependent_pairs\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:40:09.030891Z","iopub.execute_input":"2026-01-07T17:40:09.031257Z","iopub.status.idle":"2026-01-07T17:40:12.534355Z","shell.execute_reply.started":"2026-01-07T17:40:09.031230Z","shell.execute_reply":"2026-01-07T17:40:12.533589Z"}},"outputs":[{"name":"stdout","text":"\nBoundary metrics per class (averaged across vehicles):\nCut-in in front of ego vehicle: MABE = 0.22\nCut-out in front of ego vehicle: MABE = 0.14\nEgo merging into an occupied lane: MABE = 0.44\nEgo vehicle approaching slower lead vehicle: MABE = 0.19\nEgo vehicle driving in lane without lead vehicle: MABE = 0.17\nEgo vehicle overtaking vehicle in adjacent lane: MABE = 0.12\nEgo vehicle performing lane change: MABE = 0.07\nEgo vehicle performing lane change with vehicle behind: MABE = 0.10\nLead vehicle accelerating: MABE = 0.21\nLead vehicle cruising: MABE = 0.18\nLead vehicle decelerating: MABE = 0.21\nVehicle overtaking ego vehicle: MABE = 0.09\n\nAverage MABE across all classes: 0.1787\n\nMissed Scenario Detection Rates (% of vehicles where class was present but never predicted):\nCut-in in front of ego vehicle: 90.00% missed (support: 130)\nCut-out in front of ego vehicle: 91.94% missed (support: 124)\nEgo merging into an occupied lane: 95.00% missed (support: 20)\nEgo vehicle approaching slower lead vehicle: 14.93% missed (support: 201)\nEgo vehicle driving in lane without lead vehicle: 10.62% missed (support: 2637)\nEgo vehicle overtaking vehicle in adjacent lane: 26.40% missed (support: 1265)\nEgo vehicle performing lane change: 1.43% missed (support: 279)\nEgo vehicle performing lane change with vehicle behind: 27.96% missed (support: 93)\nLead vehicle accelerating: 30.60% missed (support: 696)\nLead vehicle cruising: 2.95% missed (support: 3020)\nLead vehicle decelerating: 45.24% missed (support: 588)\nVehicle overtaking ego vehicle: 7.55% missed (support: 1351)\n\nAverage Miss Rate Across All Classes (per vehicle): 37.05%\n\n\nTransition-based MABE (evaluated per vehicle):\nCut-in in front of ego vehicle -> Lead vehicle cruising: MABE = 0.72 | Support = 9 | Missed = 7 (77.8%)\nCut-out in front of ego vehicle -> Ego vehicle driving in lane without lead vehicle: MABE = nan | Support = 1 | Missed = 1 (100.0%)\nCut-out in front of ego vehicle -> Lead vehicle cruising: MABE = nan | Support = 21 | Missed = 21 (100.0%)\nEgo vehicle performing lane change -> Ego vehicle driving in lane without lead vehicle: MABE = 0.15 | Support = 2 | Missed = 0 (0.0%)\nEgo vehicle driving in lane without lead vehicle -> Lead vehicle accelerating: MABE = nan | Support = 1 | Missed = 1 (100.0%)\nEgo vehicle driving in lane without lead vehicle -> Lead vehicle cruising: MABE = 0.13 | Support = 30 | Missed = 19 (63.3%)\nEgo vehicle driving in lane without lead vehicle -> Lead vehicle decelerating: MABE = nan | Support = 1 | Missed = 1 (100.0%)\n\nAverage Transition MABE Across All Pairs: 0.3351\nOverall Missed Transition Detection Rate (per vehicle): 76.92%\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}